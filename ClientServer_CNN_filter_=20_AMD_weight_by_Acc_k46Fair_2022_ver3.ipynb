{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Bản này so với ver2: chạy theo công thức tính k1 và k2 để ra được trọng số a_i theo công thức 1 trong FAIR 2022"
      ],
      "metadata": {
        "id": "CmabFshdoHDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKWFyammktXq",
        "outputId": "6e20ba89-1880-4df9-9369-c6fdd2cbbc25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0vX9HCXxLqC"
      },
      "source": [
        "Setup model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHaomBqoxJTE"
      },
      "source": [
        "# baseline cnn model for mnist\n",
        "import pandas as pd\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "import numpy as np\n",
        "import timeit\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "cols = [2] + list(range(16386, 18264))\n",
        "def load_top3_dataset(n):\n",
        "\tfile0_df = pd.read_csv(r'/content/drive/MyDrive/Colab Notebooks/10set (cắt file >=20)/AMD_Benign(tổng hợp >= 20)/file-{}.csv'.format(n), header=None, skiprows=1, usecols=cols)\n",
        "\toutput = np.array([]).reshape(0, 1879)\n",
        "\tfor index, row in file0_df.iterrows():\n",
        "\t\tr = np.array([row])\n",
        "\t\toutput = np.concatenate((output, r), axis=0)\n",
        "\treturn output[:, 0], output[:, 1:]\n",
        "\n",
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "\t# load dataset\n",
        "\t(trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "\t# reshape dataset to have a single channel\n",
        "\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
        "\t# one hot encode target values\n",
        "\ttrainY = to_categorical(trainY)\n",
        "\ttestY = to_categorical(testY)\n",
        "\treturn trainX, trainY, testX, testY\n",
        "\n",
        "# scale pixels\n",
        "def prep_pixels(train, test):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\ttest_norm = test.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\ttest_norm = test_norm / 255.0\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm\n",
        "\n",
        "# define cnn model\n",
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\t# model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(44, 44, 1)))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dense(228, activation='softmax'))\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.01, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        "# # load dataset\n",
        "# trainX, trainY, test_X, test_Y = load_dataset()\n",
        "# # prepare pixel data\n",
        "# trainX, testX = prep_pixels(trainX, test_X)\n",
        "# # evaluate model\n",
        "# test_X, valX, test_Y, valY = train_test_split(test_X, test_Y, test_size=0.5)\n",
        "# trainX, trainX1, trainY, trainY1 = train_test_split(trainX, trainY, test_size=0.3)\n",
        "# trainX, trainX2, trainY, trainY2 = train_test_split(trainX, trainY, test_size=0.4)\n",
        "# trainX, trainX3, trainY, trainY3 = train_test_split(trainX, trainY, test_size=0.5)\n",
        "# trainX1, trainX4, trainY1, trainY4 = train_test_split(trainX1, trainY1, test_size=0.35)\n",
        "# trainX1, trainX5, trainY1, trainY5 = train_test_split(trainX1, trainY1, test_size=0.25)\n",
        "# trainX2, trainX6, trainY2, trainY6 = train_test_split(trainX2, trainY2, test_size=0.45)\n",
        "# trainX4, trainX7, trainY4, trainY7 = train_test_split(trainX4, trainY4, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8D8RKrZwCpSA"
      },
      "source": [
        "file0_y, file0_x = load_top3_dataset(0)\n",
        "file1_y, file1_x = load_top3_dataset(1)\n",
        "file2_y, file2_x = load_top3_dataset(2)\n",
        "file3_y, file3_x = load_top3_dataset(3)\n",
        "file4_y, file4_x = load_top3_dataset(4)\n",
        "file5_y, file5_x = load_top3_dataset(5)\n",
        "file6_y, file6_x = load_top3_dataset(6)\n",
        "file7_y, file7_x = load_top3_dataset(7)\n",
        "file8_y, file8_x = load_top3_dataset(8)\n",
        "file9_y, file9_x = load_top3_dataset(9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNLmhMJQT_vH"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "trainY = to_categorical(file0_y, 228)\n",
        "trainY1 = to_categorical(file1_y, 228)\n",
        "trainY2 = to_categorical(file2_y, 228)\n",
        "trainY3 = to_categorical(file3_y, 228)\n",
        "trainY4 = to_categorical(file4_y, 228)\n",
        "trainY5 = to_categorical(file5_y, 228)\n",
        "trainY6 = to_categorical(file6_y, 228)\n",
        "trainY7 = to_categorical(file7_y, 228)\n",
        "valY = to_categorical(file8_y, 228)\n",
        "test_Y = to_categorical(file9_y, 228)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kiểm tra nhãn của các file => có 38 nhãn là là tổng hợp các nhãn có từ 20file trở lên"
      ],
      "metadata": {
        "id": "zC497GAQk5oH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(file0_y, return_counts=True)\n",
        "print(\"LABEL TRAIN: \", len(unique))\n",
        "unique, counts = np.unique(file1_y, return_counts=True)\n",
        "print(\"LABEL TRAIN1: \", len(unique))\n",
        "unique, counts = np.unique(file2_y, return_counts=True)\n",
        "print(\"LABEL TRAIN2: \", len(unique))\n",
        "unique, counts = np.unique(file3_y, return_counts=True)\n",
        "print(\"LABEL TRAIN3: \", len(unique))\n",
        "unique, counts = np.unique(file4_y, return_counts=True)\n",
        "print(\"LABEL TRAIN4: \", len(unique))\n",
        "unique, counts = np.unique(file5_y, return_counts=True)\n",
        "print(\"LABEL TRAIN5: \", len(unique))\n",
        "unique, counts = np.unique(file6_y, return_counts=True)\n",
        "print(\"LABEL TRAIN6: \", len(unique))\n",
        "unique, counts = np.unique(file7_y, return_counts=True)\n",
        "print(\"LABEL TRAIN7: \", len(unique))\n",
        "unique, counts = np.unique(file8_y, return_counts=True)\n",
        "print(\"LABEL TRAIN8: \", len(unique))\n",
        "unique, counts = np.unique(file9_y, return_counts=True)\n",
        "print(\"LABEL TRAIN9: \", len(unique))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUP4Ueqsk55j",
        "outputId": "2a265a6b-d9ef-4942-a3f6-520235673323"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LABEL TRAIN:  38\n",
            "LABEL TRAIN1:  38\n",
            "LABEL TRAIN2:  38\n",
            "LABEL TRAIN3:  38\n",
            "LABEL TRAIN4:  38\n",
            "LABEL TRAIN5:  38\n",
            "LABEL TRAIN6:  38\n",
            "LABEL TRAIN7:  38\n",
            "LABEL TRAIN8:  38\n",
            "LABEL TRAIN9:  38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTvdMk-sTveE"
      },
      "source": [
        "trainX = file0_x\n",
        "trainX1 = file1_x\n",
        "trainX2 = file2_x\n",
        "trainX3 = file3_x\n",
        "trainX4 = file4_x\n",
        "trainX5 = file5_x\n",
        "trainX6 = file6_x\n",
        "trainX7 = file7_x\n",
        "valX = file8_x\n",
        "test_X = file9_x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUhpuYIeU78B"
      },
      "source": [
        "trainX = np.concatenate((trainX,np.zeros((trainX.shape[0], 58))),1)\n",
        "trainX1 = np.concatenate((trainX1,np.zeros((trainX1.shape[0], 58))),1)\n",
        "trainX2 = np.concatenate((trainX2,np.zeros((trainX2.shape[0], 58))),1)\n",
        "trainX3 = np.concatenate((trainX3,np.zeros((trainX3.shape[0], 58))),1)\n",
        "trainX4 = np.concatenate((trainX4,np.zeros((trainX4.shape[0], 58))),1)\n",
        "trainX5 = np.concatenate((trainX5,np.zeros((trainX5.shape[0], 58))),1)\n",
        "trainX6 = np.concatenate((trainX6,np.zeros((trainX6.shape[0], 58))),1)\n",
        "trainX7 = np.concatenate((trainX7,np.zeros((trainX7.shape[0], 58))),1)\n",
        "valX = np.concatenate((valX,np.zeros((valX.shape[0], 58))),1)\n",
        "test_X = np.concatenate((test_X,np.zeros((test_X.shape[0], 58))),1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAgl9XHLVUTf"
      },
      "source": [
        "trainX = trainX.reshape(trainX.shape[0],44, 44, 1)\n",
        "trainX1 = trainX1.reshape(trainX1.shape[0],44, 44, 1)\n",
        "trainX2 = trainX2.reshape(trainX2.shape[0],44, 44, 1)\n",
        "trainX3 = trainX3.reshape(trainX3.shape[0],44, 44, 1)\n",
        "trainX4 = trainX4.reshape(trainX4.shape[0],44, 44, 1)\n",
        "trainX5 = trainX5.reshape(trainX5.shape[0],44, 44, 1)\n",
        "trainX6 = trainX6.reshape(trainX6.shape[0],44, 44, 1)\n",
        "trainX7 = trainX7.reshape(trainX7.shape[0],44, 44, 1)\n",
        "valX = valX.reshape(valX.shape[0],44, 44, 1)\n",
        "test_X = test_X.reshape(test_X.shape[0],44, 44, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6EQgfqFqFlE"
      },
      "source": [
        "Check shape of input dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7xgj_vGgawN",
        "outputId": "d698bf18-ff05-4388-ef7e-ef54704d27e3"
      },
      "source": [
        "print(trainX.shape)\n",
        "print(trainX1.shape)\n",
        "print(trainX2.shape)\n",
        "print(trainX3.shape)\n",
        "print(trainX4.shape)\n",
        "print(trainX5.shape)\n",
        "print(trainX6.shape)\n",
        "print(trainX7.shape)\n",
        "print(valX.shape)\n",
        "print(test_X.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2558, 44, 44, 1)\n",
            "(2558, 44, 44, 1)\n",
            "(2558, 44, 44, 1)\n",
            "(2558, 44, 44, 1)\n",
            "(2558, 44, 44, 1)\n",
            "(2558, 44, 44, 1)\n",
            "(2558, 44, 44, 1)\n",
            "(2558, 44, 44, 1)\n",
            "(2558, 44, 44, 1)\n",
            "(2705, 44, 44, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHStyegMNFFy"
      },
      "source": [
        "Step 1: \n",
        "    for 1/10 dataset train for server (sv)\n",
        "    for 1/10 dataset train for client 1 (c1)\n",
        "    for 1/10 dataset train for client 2 (c2)\n",
        "    for 1/10 dataset train for client 3 (c3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlS-zCgh-EKs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "922ba9dd-39ef-4f2e-eae5-a14ce55ea524"
      },
      "source": [
        "c1 = define_model()\n",
        "c2 = define_model()\n",
        "c3 = define_model()\n",
        "sv = define_model()\n",
        "\n",
        "start = timeit.default_timer()\n",
        "sv.fit(trainX, trainY, epochs=70, batch_size=512, validation_data=(valX, valY), verbose=0)\n",
        "end = timeit.default_timer()\n",
        "print('time_Server: {}'.format(end-start))\n",
        "\n",
        "start = timeit.default_timer()\n",
        "c1.fit(trainX1, trainY1, epochs=70, batch_size=512, validation_data=(valX, valY), verbose=0)\n",
        "end = timeit.default_timer()\n",
        "print('time_C1: {}'.format(end-start))\n",
        "\n",
        "start = timeit.default_timer()\n",
        "c2.fit(trainX2, trainY2, epochs=70, batch_size=512, validation_data=(valX, valY), verbose=0)\n",
        "end = timeit.default_timer()\n",
        "print('time_C2: {}'.format(end-start))\n",
        "\n",
        "start = timeit.default_timer()\n",
        "c3.fit(trainX3, trainY3, epochs=70, batch_size=512, validation_data=(valX, valY), verbose=0)\n",
        "end = timeit.default_timer()\n",
        "print('time_C3: {}'.format(end-start))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time_Server: 41.59386244900003\n",
            "time_C1: 10.594889479000017\n",
            "time_C2: 10.020363006000025\n",
            "time_C3: 10.59864388599999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-PNQFLkNmFD"
      },
      "source": [
        "Test Step 1: Test model in server and clients (c1, c2, c3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r38KhdGcgsnD",
        "outputId": "7d55f163-5230-4e4f-bcc3-8889b4f36939"
      },
      "source": [
        "\n",
        "print(\"==============train result=============\")\n",
        "y_pred = sv.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Acc_Server: ', accuracy_score(y_pred1, y_pred))\n",
        "acc_s = accuracy_score(y_pred1, y_pred)\n",
        "\n",
        "y_pred = c1.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Acc_C1: ', accuracy_score(y_pred1, y_pred))\n",
        "acc_1 = accuracy_score(y_pred1, y_pred)\n",
        "\n",
        "y_pred = c2.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Acc_C2: ', accuracy_score(y_pred1, y_pred))\n",
        "acc_2 = accuracy_score(y_pred1, y_pred)\n",
        "\n",
        "y_pred = c3.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Acc_C3: ', accuracy_score(y_pred1, y_pred))\n",
        "acc_3 = accuracy_score(y_pred1, y_pred)\n",
        "print(\"========================================\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============train result=============\n",
            "Acc_Server:  0.9449168207024029\n",
            "Acc_C1:  0.9534195933456562\n",
            "Acc_C2:  0.9500924214417745\n",
            "Acc_C3:  0.9523105360443623\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SHoaLz9OKRD"
      },
      "source": [
        "Step 2: update weight_avg; k1 = 0.4; k2 = 0.6"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k1 = 0.4\n",
        "k2= 0.6"
      ],
      "metadata": {
        "id": "SKLKk5inCtyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_D = trainX.shape[0] + trainX1.shape[0] +trainX2.shape[0] + trainX3.shape[0]\n",
        "total_acc = acc_s + acc_1 + acc_2 + acc_3\n",
        "a_s = (k1 * trainX.shape[0]/total_D) + (k2*acc_s/total_acc)\n",
        "a_1 = (k1 * trainX1.shape[0]/total_D) + (k2*acc_1/total_acc)\n",
        "a_2 = (k1 * trainX2.shape[0]/total_D) + (k2*acc_2/total_acc)\n",
        "a_3 = (k1 * trainX3.shape[0]/total_D) + (k2*acc_3/total_acc)\n",
        "print(\"a_s = \", a_s)\n",
        "print(\"a_1 = \", a_1)\n",
        "print(\"a_2 = \", a_2)\n",
        "print(\"a_3 = \", a_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEm2UH4QCUrc",
        "outputId": "1936d9b4-3f40-4b18-e6bf-2ffc6a76026e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a_s =  0.24916836883571636\n",
            "a_1 =  0.25051065071491097\n",
            "a_2 =  0.24998540997957397\n",
            "a_3 =  0.2503355704697987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IliZG0RTSdTL",
        "outputId": "9a496e60-2f93-41de-cc41-cc8e13f7db1a"
      },
      "source": [
        "avg = a_s*np.array(sv.get_weights())+a_1*np.array(c1.get_weights()) + a_2*np.array(c2.get_weights()) + a_3*np.array(c3.get_weights())\n",
        "c1.set_weights(avg)\n",
        "c2.set_weights(avg)\n",
        "c3.set_weights(avg)\n",
        "sv.set_weights(avg)\n",
        "print(\"==============Result with weight_Avg=============\")\n",
        "y_pred = sv.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Acc_Server: ', accuracy_score(y_pred1, y_pred))\n",
        "y_pred = c1.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Acc_Client 1 (c1): ', accuracy_score(y_pred1, y_pred))\n",
        "print(\"========================================\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============Result with weight_Avg=============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc_Server:  0.3009242144177449\n",
            "Acc_Client 1 (c1):  0.3009242144177449\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqM-YblUN9OS"
      },
      "source": [
        "Step 3: train client 1 and client 2 with new dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0amqONBTccC",
        "outputId": "0f305e2d-e439-46a2-8d88-92c6b1809604"
      },
      "source": [
        "start = timeit.default_timer()\n",
        "c1.fit(trainX4, trainY4, epochs=70, batch_size=512, validation_data=(valX, valY), verbose=0)\n",
        "end = timeit.default_timer()\n",
        "print('time_C1: {}'.format(end-start))\n",
        "\n",
        "start = timeit.default_timer()\n",
        "c2.fit(trainX5, trainY5, epochs=70, batch_size=512, validation_data=(valX, valY), verbose=0)\n",
        "end = timeit.default_timer()\n",
        "print('time_C2: {}'.format(end-start))\n",
        "\n",
        "print(\"==============train result=============\")\n",
        "y_pred = sv.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Acc_Server: ', accuracy_score(y_pred1, y_pred))\n",
        "acc_s = accuracy_score(y_pred1, y_pred)\n",
        "\n",
        "y_pred = c1.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Acc_C1: ', accuracy_score(y_pred1, y_pred))\n",
        "acc_1 = accuracy_score(y_pred1, y_pred)\n",
        "\n",
        "y_pred = c2.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Acc_C2: ', accuracy_score(y_pred1, y_pred))\n",
        "acc_2 = accuracy_score(y_pred1, y_pred)\n",
        "\n",
        "y_pred = c3.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Acc_C3: ', accuracy_score(y_pred1, y_pred))\n",
        "acc_3 = accuracy_score(y_pred1, y_pred)\n",
        "print(\"========================================\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time_C1: 10.298040096999955\n",
            "time_C2: 9.603655690999972\n",
            "==============train result=============\n",
            "Acc_Server:  0.3009242144177449\n",
            "Acc_C1:  0.9486136783733826\n",
            "Acc_C2:  0.9478743068391867\n",
            "Acc_C3:  0.3009242144177449\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ijfwxVXO0iI"
      },
      "source": [
        "Step 4: update weight_avg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_D = trainX4.shape[0] +trainX5.shape[0]\n",
        "total_acc = acc_1 + acc_2\n",
        "\n",
        "a_1 = (k1 * trainX4.shape[0]/total_D) + (k2*acc_1/total_acc)\n",
        "a_2 = (k1 * trainX5.shape[0]/total_D) + (k2*acc_2/total_acc)\n",
        "\n",
        "\n",
        "print(\"a_1 = \", a_1)\n",
        "print(\"a_2 = \", a_2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW7UG57-FdTs",
        "outputId": "0bce0ae6-4799-4e9f-ce6b-a8e6178bfea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a_1 =  0.5001169590643275\n",
            "a_2 =  0.49988304093567254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSIm6rBRYKDB",
        "outputId": "45c58a68-0759-4135-a2a1-25238630435e"
      },
      "source": [
        "\n",
        "avg = a_1*np.array(c1.get_weights()) + a_2*np.array(c2.get_weights())\n",
        "\n",
        "c1.set_weights(avg)\n",
        "c2.set_weights(avg)\n",
        "c3.set_weights(avg)\n",
        "sv.set_weights(avg)\n",
        "print(\"==============Result Avg=============\")\n",
        "y_pred = sv.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Acc_Server: ', accuracy_score(y_pred1, y_pred))\n",
        "y_pred = c1.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Acc_Client 1: ', accuracy_score(y_pred1, y_pred))\n",
        "print(\"========================================\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============Result Avg=============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc_Server:  0.9493530499075785\n",
            "Acc_Client 1:  0.9493530499075785\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPdYsF4vPFQC"
      },
      "source": [
        "Step 5: Next, train client 1 and client 2, no train server and client 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hQZVezQUGu5",
        "outputId": "9ee7bcae-4857-49d9-87d7-9bf4b3c48b0b"
      },
      "source": [
        "start = timeit.default_timer()\n",
        "c1.fit(trainX6, trainY6, epochs=70, batch_size=512, validation_data=(valX, valY), verbose=0)\n",
        "end = timeit.default_timer()\n",
        "print('time_C1: {}'.format(end-start))\n",
        "\n",
        "start = timeit.default_timer()\n",
        "c2.fit(trainX7, trainY7, epochs=70, batch_size=512, validation_data=(valX, valY), verbose=0)\n",
        "end = timeit.default_timer()\n",
        "print('time_C2: {}'.format(end-start))\n",
        "\n",
        "print(\"==============Result train=============\")\n",
        "y_pred = sv.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Acc_Server: ', accuracy_score(y_pred1, y_pred))\n",
        "acc_s = accuracy_score(y_pred1, y_pred)\n",
        "\n",
        "y_pred = c1.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Acc_C1: ', accuracy_score(y_pred1, y_pred))\n",
        "acc_1 = accuracy_score(y_pred1, y_pred)\n",
        "\n",
        "y_pred = c2.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Acc_C2: ', accuracy_score(y_pred1, y_pred))\n",
        "acc_2 = accuracy_score(y_pred1, y_pred)\n",
        "\n",
        "y_pred = c3.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Acc_C3: ', accuracy_score(y_pred1, y_pred))\n",
        "acc_3 = accuracy_score(y_pred1, y_pred)\n",
        "print(\"========================================\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time_C1: 10.28455448599999\n",
            "time_C2: 10.056869661000007\n",
            "==============Result train=============\n",
            "Acc_Server:  0.9493530499075785\n",
            "Acc_C1:  0.9641404805914973\n",
            "Acc_C2:  0.9652495378927911\n",
            "Acc_C3:  0.9493530499075785\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12-B7Dh0PqKP"
      },
      "source": [
        "Step 5_3: update weight for all computer and check result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_D = trainX6.shape[0] +trainX7.shape[0]\n",
        "total_acc = acc_1 + acc_2\n",
        "a_1 = (k1 * trainX6.shape[0]/total_D) + (k2*acc_1/total_acc)\n",
        "a_2 = (k1 * trainX7.shape[0]/total_D) + (k2*acc_2/total_acc)\n",
        "print(\"a_1 = \", a_1)\n",
        "print(\"a_2 = \", a_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBc77BSaGPMT",
        "outputId": "a66a5ec3-7068-4930-d1c5-90d936a8206c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a_1 =  0.49982755317110555\n",
            "a_2 =  0.5001724468288944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uW0nbJyZmXOC",
        "outputId": "5cdd594f-ffe8-46fe-97b0-c6b483cef036"
      },
      "source": [
        "avg = a_1*np.array(c1.get_weights()) + a_2*np.array(c2.get_weights())\n",
        "\n",
        "c1.set_weights(avg)\n",
        "c2.set_weights(avg)\n",
        "c3.set_weights(avg)\n",
        "sv.set_weights(avg)\n",
        "print(\"==============result Avg=============\")\n",
        "y_pred = sv.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Acc_erver: ', accuracy_score(y_pred1, y_pred))\n",
        "y_pred = c1.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Acc_Client 1: ', accuracy_score(y_pred1, y_pred))\n",
        "print(\"========================================\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============result Avg=============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc_erver:  0.9685767097966729\n",
            "Acc_Client 1:  0.9685767097966729\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxiI-1WDQHHD"
      },
      "source": [
        "Step 6: Reuslt when train one computer which full dataset train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvizyRwRphu9",
        "outputId": "afa0486f-f9c5-41d6-8026-18560fa51277"
      },
      "source": [
        "x = np.concatenate((trainX, trainX1, trainX2, trainX3, trainX4, trainX5, trainX6, trainX7), axis=0)\n",
        "y = np.concatenate((trainY, trainY1, trainY2, trainY3, trainY4, trainY5, trainY6, trainY7), axis=0)\n",
        "start = timeit.default_timer()\n",
        "model = define_model()\n",
        "model.fit(x, y, epochs=70, batch_size=512, validation_data=(valX, valY), verbose=0)\n",
        "print(\"==============Result with one computer=============\")\n",
        "y_pred = model.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Result Acc: ', accuracy_score(y_pred1, y_pred))\n",
        "end = timeit.default_timer()\n",
        "print('time train full: {}'.format(end-start))\n",
        "print(\"========================================\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============Result with one computer=============\n",
            "Result Acc:  0.9855822550831793\n",
            "time train full: 82.83571486399995\n",
            "========================================\n"
          ]
        }
      ]
    }
  ]
}